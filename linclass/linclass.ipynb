{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification\n",
    "George Ho 10/19/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "pi = 0.4\n",
    "mu1 = np.ones(2)\n",
    "mu2 = -np.ones(2)\n",
    "sigma = np.identity(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "train_class1 = np.random.multivariate_normal(mu1, sigma, round(500*pi))\n",
    "train_class2 = np.random.multivariate_normal(mu2, sigma, round(500*(1-pi)))\n",
    "\n",
    "train_binary_data = np.vstack([train_class1, train_class2])\n",
    "train_class_label = np.hstack([np.ones(round(500*pi)), np.zeros(round(500*(1-pi)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_class1 = np.random.multivariate_normal(mu1, sigma, round(100*pi))\n",
    "test_class2 = np.random.multivariate_normal(mu2, sigma, round(100*(1-pi)))\n",
    "\n",
    "test_binary_data = np.vstack([test_class1, test_class2])\n",
    "test_class_labels = np.hstack([np.ones(round(100*pi)), np.zeros(round(100*(1-pi)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model: Gaussian Class-Conditional Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ML estimation of pi, mu1, mu2\n",
    "\n",
    "pi_est = np.count_nonzero(train_class_label)/train_class_label.size\n",
    "mu1_est = train_binary_data[train_class_label == 1].mean(axis=0)\n",
    "mu2_est = train_binary_data[train_class_label == 0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There is probably a better way of doing this... but idk\n",
    "\n",
    "# Computing S1\n",
    "vectors1 = train_binary_data[train_class_label == 1] - mu1_est\n",
    "foo = np.zeros([len(vectors1), 2, 2])\n",
    "for i, row in enumerate(vectors1):\n",
    "    foo[i] = np.outer(row, row)\n",
    "S1 = foo.mean(axis=0)\n",
    "\n",
    "# Computing S2\n",
    "vectors2 = train_binary_data[train_class_label == 0] - mu2_est\n",
    "bar = np.zeros([len(vectors2), 2, 2])\n",
    "for i, row in enumerate(vectors2):\n",
    "    bar[i] = np.outer(row, row)\n",
    "S2 = bar.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ML estimation of sigma\n",
    "\n",
    "N1 = train_binary_data[train_class_label == 1].size\n",
    "N2 = train_binary_data[train_class_label == 0].size\n",
    "sigma_est = (N1/(N1+N2))*S1 + (N2/(N1+N2))*S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.linalg.inv(sigma_est) @ (mu1_est-mu2_est)\n",
    "w_0 = - 0.5*(mu1_est.T @ np.linalg.inv(sigma_est) @ mu1_est) \\\n",
    "      + 0.5*(mu2_est.T @ np.linalg.inv(sigma_est) @ mu2_est) \\\n",
    "      + np.log(pi_est / (1-pi_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def posterior_probability(x):\n",
    "    return sigmoid(w@x + w_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_decisions = list(map(lambda x: 1 if posterior_probability(x) > 0.5 else 0, test_binary_data))\n",
    "\n",
    "success = class_decisions == test_class_labels\n",
    "misclassification_rate = (success.size - np.count_nonzero(success)) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Model: Iteratively Reweighted Logistic Regression\n",
    "\n",
    "_Without_ nonlinear basis functions... Just by graphing the training data, it looks like they're pretty linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial guess\n",
    "w = np.atleast_2d(np.ones([3,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "phi = np.ones([500, 3])\n",
    "phi[:, 1:] = train_binary_data\n",
    "t = train_class_label.reshape(500, 1)\n",
    "\n",
    "for _ in range(100):\n",
    "    y = sigmoid((w.T*phi).sum(axis=1)).reshape([500,1])\n",
    "    R = np.diag(np.multiply(y, 1-y).flatten())\n",
    "    z = phi @ w - np.linalg.inv(R) @ (y - t)\n",
    "    w = np.linalg.inv(phi.T @ R @ phi) @ phi.T @ R @ z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def posterior_probability(x):\n",
    "    return sigmoid(np.multiply(w.T, x).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_phi = np.ones([100, 3])\n",
    "test_phi[:, 1:] = test_binary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_decisions = list(map(lambda x: 1 if posterior_probability(x) > 0.5 else 0, test_phi))\n",
    "\n",
    "success = class_decisions == test_class_labels\n",
    "misclassification_rate = (success.size - np.count_nonzero(success)) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
